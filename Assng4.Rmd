---
title: "Assng4"
author: "Saira Asif"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(rpart)
library(tree)
#install.packages("rpart.plot")
library(rpart.plot)
library(lars)
library(glmnet)
library(caret)
library(plotly)
library(randomForest)
library(ipred)
library(Metrics)
```

## DATA

```{r}
# reading in training and testing dataset
tumor_train <- read_csv("/Users/sairaasif49/Downloads/trainset.csv")
tumor_test <- read_csv("/Users/sairaasif49/Downloads/testset.csv")

# No missing/NA values is any columns
apply(tumor_train, 2, function(x){sum(is.na(x))})

# No 0s in the predictor columns
apply(tumor_train, 2, function(x){sum(x==0)})

#convert status to factor
tumor_train$status<-as.factor(tumor_train$status)
tumor_test$status<-as.factor(tumor_test$status)
```

## elastic net (include Lasso and Ridge in your search grid) (Saira )

LASSO package glmnet requires the the response variable to be a vector and the set of predictor variables to be of the class data.matrix.

```{r}
#define response variable as vector 
status <- tumor_train$status
# dim is NULL as it is a vector, not a matrix
dim(status)

#define matrix of predictor variables
xs <- data.matrix(tumor_train[, -1])
dim(xs)
# Variance is different across predictors, so it has not been standardized, however glmnet automatically standardizes the variables
apply(xs, 2, var)

# ELASTIC NET

set.seed(12)

#efine the type of re-sampling as cross-validation using 10-fold method
enet <- trainControl(method = "cv", number = 10)

# Allows us to have more alpha values, from 0 to 1, to include both lasso and ridge regression in the analysis.
elasticGrid <- expand.grid(.alpha = seq(0, 1, length = 10), .lambda = seq(.5, 7.5, 1))
elasticGrid <- expand.grid(.alpha = seq(0, 1, length = 10), .lambda = seq(0, 1, length =10))
#cv.glmnet for computing penalized linear regression models.
def_elnet = train(status ~ ., data=tumor_train, method = "glmnet", trControl = enet, tuneGrid = elasticGrid)

# results for each combination of alpha and lambda
def_elnet$results

#lower alpha and lambda - better models
par(mfrow = c(1,2))
plot(def_elnet$results[ ,c(1,3)])
plot(def_elnet$results[ ,c(2,3)])

## highest possible Accuracy - best model
max_acc <- which.max(def_elnet$results[ ,3])
def_elnet$results[max_acc,] 

# ridge regression seems the best for this dataset
def_elnet$bestTune

#perform k-fold cross-validation to find optimal lambda value that minimizes PE/MSE
cv_model <- cv.glmnet(xs, status, type.measure = "class", family = "binomial")
plot(cv_model)
coef(cv_model,s = c(cv_model$lambda.min,cv_model$lambda.1se))

prd.fl <- predict(cv_model, newx = data.matrix(tumor_test[,-1]), s = c(cv_model$lambda.min, cv_model$lambda.1se)) 

```



## KNN (Lisa)



## a fully grown classification/regression tree (CART) (Saira)

The training set is used to build a classification trees. 

```{r}

# Fitting a classification tree to tumor dataset
class_tree <- rpart(status ~ ., data=tumor_train, method = "class")

summary(class_tree)

# Visualizing the unpruned tree
rpart.plot(class_tree)


# Checking the order of variable importance
class_tree$variable.importance

# Checking model fit on testing dataset
pred_tree = predict(class_tree, tumor_test, type = "class")

# Compairing the preditced reuslt w
table_fit <- table(pred_tree,tumor_test$status)  ################# could also just do confusionMatrix(table(pred_tree,tumor_test$status)) to get stats on model

TP = table_fit[1]
TN = table_fit[2,2]
FN = table_fit[2]
FP =  table_fit[1,2]

#Accuracy of the model is 90.58824
(Acc = (TP+TN)/(TP+TN+FP+FN)) * 100

#Sensitivity of model is 88.33333
(SEN = TP/(TP+FN)) * 100

# Specificity of the model is  96
(SPES = TN/(TN+FP)) * 100


```

We can also check if pruning the tree will improve results. Pruning selects the cp (complexity parameter) value associated with a shorter tree that minimizes the cross-validated error rate (xerror). 

```{r}
# Checking if pruning will improve results 
#plotcp(fit.tree)
printcp(class_tree)

# Explicitly request the lowest cp value
bestcp <- class_tree$cptable[which.min(class_tree$cptable[,"xerror"]),"CP"]
pruned_tree <- prune(class_tree, cp = bestcp)
rpart.plot(pruned_tree)

# Alternate specification 
pred_prune = predict(pruned_tree, tumor_test, type="class")

pruned_table <- table(pred_prune, tumor_test$status)

TP2 = pruned_table[1]
TN2 = pruned_table[2,2]
FN2 = pruned_table[2]
FP2 =  pruned_table[1,2]

#Accuracy of the model is 90.58824
(Acc2 = (TP2+TN2)/(TP2+TN2+FP2+FN2)) * 100

#Sensitivity of model is 68.83117

(SEN2 = TP2/(TP2+FN2)) * 100

# Specificity of the model is  96
(SPES2 = TN2/(TN2+FP2)) * 100


```
There is no change in classification after pruning the tree. This suggests that pruning is not necessary for this tree


## support vector machine (Lisa)



## a bagged version of CART (Zee)
```{r}
##bagging regression trees with 150 bootstrap replications
set.seed(123)
bag<-bagging(status~., data=tumor_train, nbagg=150, coob=T)
bag
#Out-of-bag estimate of misclassification error:  0.0455

#most import variables for model
imp <- data.frame(var=names(tumor_train[,-1]), imp=varImp(bag))

#sort variable importance descending
VI_plot <- imp[order(imp$Overall, decreasing=TRUE),]

#visualize variable importance with horizontal bar plot
barplot(VI_plot$Overall,
        names.arg=rownames(VI_plot),
        horiz=TRUE,
        col='steelblue',
        xlab='Variable Importance')

bag_CART_pred<-predict(bag, newdata=tumor_test, type="class")

#confusionmatrix
confusionMatrix(table(bag_CART_pred,tumor_test$status))
#Accuracy=92.94%
#Sensitivity=93.33%
#Specificity=92%
```



## random forests. (Zee)
```{r}
#for reproducible results
set.seed(751)

#Creating random forest model
randomforest_model<-randomForest(status~., data=tumor_train)
randomforest_model
#random forest classification with 500 trees generated at each node, which splits into 5 smaller nodes

#visualization of most important variables in the model
varImpPlot(randomforest_model) 

#testing the model on unseen data
randomforest_test <- predict(randomforest_model, newdata = tumor_test, type= "class")

#Confusion matrix
confusionMatrix(table(randomforest_test,tumor_test$status)) 
###Accuracy= 94%
##Sensitivity= 95%
##Specificity= 92%  
```

## Final table 


